{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene-to-graph workflow\n",
    "\n",
    "This notebook showcases the steps to generate the BioDataFuse data and graph serializations from a list of genes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /home/javi/pyBiodatafuse-4\n"
     ]
    }
   ],
   "source": [
    "# Setting up the working directory\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "os.chdir(os.path.join(f\"{current_dir}\", \"..\"))\n",
    "\n",
    "# Set the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from pyBiodatafuse import id_mapper\n",
    "from pyBiodatafuse.annotators import (\n",
    "    bgee,\n",
    "    disgenet,\n",
    "    minerva,\n",
    "    molmedb,\n",
    "    opentargets,\n",
    "    pubchem,\n",
    "    stringdb,\n",
    "    wikipathways,\n",
    ")\n",
    "from pyBiodatafuse.constants import DISGENET_DISEASE_COL\n",
    "from pyBiodatafuse.graph import generator\n",
    "from pyBiodatafuse.graph.rdf import BDFGraph\n",
    "from pyBiodatafuse.utils import (\n",
    "    combine_sources,\n",
    "    create_harmonized_input_file,\n",
    "    create_or_append_to_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entity resolution with BridgeDB\n",
    "\n",
    "The first step is to input the list of genes to query and retrieve their protein target and synonym identifiers using BridgeDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the input list and convert it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "identifier",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c4df6470-a6dd-4258-a62b-2194f2af384a",
       "rows": [
        [
         "0",
         "ENSG00000139618"
        ],
        [
         "1",
         ""
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000139618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        identifier\n",
       "0  ENSG00000139618\n",
       "1                 "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_of_interest = \"\"\"BRCA2\n",
    "\"\"\"\n",
    "\n",
    "gene_list = genes_of_interest.split(\"\\n\")\n",
    "data_input = pd.DataFrame(gene_list, columns=[\"identifier\"])\n",
    "data_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Query BridgeDB\n",
    "The results will be stored in the following directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(\"examples\", \"data\"), exist_ok=True)  # TODO paths\n",
    "os.makedirs(os.path.join(\"examples\", \"data\", \"gene_to_graph_workflow\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(os.getcwd())  # Ensures an absolute path\n",
    "pickle_path = os.path.join(base_dir, \"examples\", \"data\", \"example_gene_list.pkl\")\n",
    "metadata_path = os.path.join(base_dir, \"examples\", \"data\", \"example_gene_list_metadata.pkl\")\n",
    "\n",
    "if not os.path.exists(pickle_path):\n",
    "    bridgedb_df, bridgedb_metadata = id_mapper.bridgedb_xref(\n",
    "        identifiers=data_input,\n",
    "        input_species=\"Human\",\n",
    "        input_datasource=\"HGNC\",\n",
    "        output_datasource=\"All\",\n",
    "    )\n",
    "    bridgedb_df.to_pickle(pickle_path)\n",
    "    with open(metadata_path, \"wb\") as file:\n",
    "        pickle.dump(bridgedb_metadata, file)\n",
    "else:\n",
    "    bridgedb_df = pd.read_pickle(pickle_path)\n",
    "    with open(metadata_path, \"rb\") as file:\n",
    "        bridgedb_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also skip `input_datasource` for most identifier types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "identifier.source",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "target",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "target.source",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "identifier",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e87c0ac7-a3b8-471a-9575-bf5d50ca13c9",
       "rows": [],
       "shape": {
        "columns": 4,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier.source</th>\n",
       "      <th>target</th>\n",
       "      <th>target.source</th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [identifier.source, target, target.source, identifier]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bridgedb_df_test, bridgedb_metadata_test = id_mapper.bridgedb_xref(\n",
    "    identifiers=data_input,\n",
    "    input_species=\"Human\",\n",
    "    # input_datasource=\"HGNC\", # Commented out\n",
    "    output_datasource=\"All\",\n",
    ")\n",
    "bridgedb_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes with mapping in BridgeDb: 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "identifier.source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "target.source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6bf3e18f-f83c-4c6c-8417-fe607b358d1b",
       "rows": [
        [
         "0",
         "SETD1A",
         "HGNC",
         "3656701",
         "Affy"
        ],
        [
         "1",
         "SETD1A",
         "HGNC",
         "uc289eha.1",
         "UCSC Genome Browser"
        ],
        [
         "2",
         "SETD1A",
         "HGNC",
         "3656702",
         "Affy"
        ],
        [
         "3",
         "SETD1A",
         "HGNC",
         "3656700",
         "Affy"
        ],
        [
         "4",
         "SETD1A",
         "HGNC",
         "XP_006721169",
         "RefSeq"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>identifier.source</th>\n",
       "      <th>target</th>\n",
       "      <th>target.source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SETD1A</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>3656701</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SETD1A</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>uc289eha.1</td>\n",
       "      <td>UCSC Genome Browser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SETD1A</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>3656702</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SETD1A</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>3656700</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SETD1A</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>XP_006721169</td>\n",
       "      <td>RefSeq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identifier identifier.source        target        target.source\n",
       "0     SETD1A              HGNC       3656701                 Affy\n",
       "1     SETD1A              HGNC    uc289eha.1  UCSC Genome Browser\n",
       "2     SETD1A              HGNC       3656702                 Affy\n",
       "3     SETD1A              HGNC       3656700                 Affy\n",
       "4     SETD1A              HGNC  XP_006721169               RefSeq"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of genes with mapping in BridgeDb:\", len(bridgedb_df[\"identifier\"].unique()))\n",
    "bridgedb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gene expression\n",
    "### 2.1. Gene expression from Bgee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgee_path = os.path.join(base_dir, \"examples\", \"data\", \"example_bgee.pkl\")\n",
    "bgee_metadata_path = os.path.join(base_dir, \"examples\", \"data\", \"example_bgee_metadata.pkl\")\n",
    "\n",
    "if not os.path.exists(bgee_path):\n",
    "    bgee_df, bgee_metadata = bgee.get_gene_expression(bridgedb_df=bridgedb_df)\n",
    "    bgee_df.to_pickle(bgee_path)\n",
    "    with open(bgee_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(bgee_metadata, file)\n",
    "else:\n",
    "    bgee_df = pd.read_pickle(bgee_path)\n",
    "    with open(bgee_metadata_path, \"rb\") as file:\n",
    "        bgee_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Disease annotation\n",
    "### 3.1. Gene to disease annotation with DisGeNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dotenv\n",
    "\n",
    "# disgenet_api_key = dotenv.dotenv_values(\".env\")[\"DISGENET_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'disgenet_api_key' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m disgenet_metadata_path = os.path.join(base_dir, \u001b[33m\"\u001b[39m\u001b[33mexamples\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mexample_disgenet_metadata.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(disgenet_path):\n\u001b[32m      6\u001b[39m     disgenet_df, disgenet_metadata = disgenet.get_gene_disease(\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         api_key=\u001b[43mdisgenet_api_key\u001b[49m, bridgedb_df=bridgedb_df\n\u001b[32m      8\u001b[39m     )\n\u001b[32m     10\u001b[39m     disgenet_df.to_pickle(disgenet_path)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(disgenet_metadata_path, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "\u001b[31mNameError\u001b[39m: name 'disgenet_api_key' is not defined"
     ]
    }
   ],
   "source": [
    "disgenet_path = os.path.join(base_dir, \"examples\", \"data\", \"example_disgenet.pkl\")\n",
    "disgenet_metadata_path = os.path.join(base_dir, \"examples\", \"data\", \"example_disgenet_metadata.pkl\")\n",
    "\n",
    "\n",
    "if not os.path.exists(disgenet_path):\n",
    "    disgenet_df, disgenet_metadata = disgenet.get_gene_disease(\n",
    "        api_key=disgenet_api_key, bridgedb_df=bridgedb_df\n",
    "    )\n",
    "\n",
    "    disgenet_df.to_pickle(disgenet_path)\n",
    "    with open(disgenet_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(disgenet_metadata, file)\n",
    "else:\n",
    "    disgenet_df = pd.read_pickle(disgenet_path)\n",
    "    with open(disgenet_metadata_path, \"rb\") as file:\n",
    "        disgenet_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Disease to compound annotation from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input to use DISGENET output as seed for OpenTargets\n",
    "disease_mapping_df = create_harmonized_input_file(disgenet_df, DISGENET_DISEASE_COL, \"EFO\", \"UMLS\")\n",
    "disease_mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentarget_path = os.path.join(base_dir, \"examples\", \"data\", \"example_opentarget_cmpd.pkl\")\n",
    "opentarget_metadata_path = os.path.join(\n",
    "    base_dir, \"examples\", \"data\", \"example_opentarget_cmpd_metadata.pkl\"\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(opentarget_path):\n",
    "    opentargets_df, opentargets_metadata = opentargets.get_disease_compound_interactions(\n",
    "        disease_mapping_df\n",
    "    )\n",
    "    opentargets_df.to_pickle(opentarget_path)\n",
    "    with open(opentarget_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(opentargets_metadata, file)\n",
    "else:\n",
    "    opentargets_df = pd.read_pickle(opentarget_path)\n",
    "    with open(opentarget_metadata_path, \"rb\") as file:\n",
    "        opentargets_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pathways and Gene Ontology terms\n",
    "### 4.1. Pathways from MINERVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerva_path = os.path.join(base_dir, \"examples\", \"data\", \"example_minerva.pkl\")\n",
    "minerva_metadata_path = os.path.join(base_dir, \"examples\", \"data\", \"example_minerva_metadata.pkl\")\n",
    "\n",
    "\n",
    "if not os.path.exists(minerva_path):\n",
    "    minerva_df, minerva_metadata = minerva.get_gene_minerva_pathways(\n",
    "        bridgedb_df, map_name=\"COVID19 Disease Map\"\n",
    "    )\n",
    "    minerva_df.to_pickle(minerva_path)\n",
    "    with open(minerva_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(minerva_metadata, file)\n",
    "\n",
    "else:\n",
    "    minerva_df = pd.read_pickle(minerva_path)\n",
    "    with open(minerva_metadata_path, \"rb\") as file:\n",
    "        minerva_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Pathways from WikiPathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipathways_path = os.path.join(base_dir, \"examples\", \"data\", \"example_wikipathway.pkl\")\n",
    "wikipathways_metadata_path = os.path.join(\n",
    "    base_dir, \"examples\", \"data\", \"example_wikipathway_metadata.pkl\"\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(wikipathways_path):\n",
    "    wikipathways_df, wikipathways_metadata = wikipathways.get_gene_wikipathways(\n",
    "        bridgedb_df=bridgedb_df\n",
    "    )\n",
    "    wikipathways_df.to_pickle(wikipathways_path)\n",
    "    with open(wikipathways_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(wikipathways_metadata, file)\n",
    "\n",
    "else:\n",
    "    wikipathways_df = pd.read_pickle(wikipathways_path)\n",
    "    with open(wikipathways_metadata_path, \"rb\") as file:\n",
    "        wikipathways_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Reactome pathways from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentargets_reactome_path = os.path.join(base_dir, \"examples\", \"data\", \"example_ot_reactome.pkl\")\n",
    "opentargets_reactome_metadata_path = os.path.join(\n",
    "    base_dir, \"examples\", \"data\", \"example_ot_reactome_metadata.pkl\"\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(opentargets_reactome_path):\n",
    "    opentargets_reactome_df, opentargets_reactome_metadata = opentargets.get_gene_reactome_pathways(\n",
    "        bridgedb_df=bridgedb_df\n",
    "    )\n",
    "    opentargets_reactome_df.to_pickle(opentargets_reactome_path)\n",
    "    with open(opentargets_reactome_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(opentargets_reactome_metadata, file)\n",
    "else:\n",
    "    opentargets_reactome_df = pd.read_pickle(opentargets_reactome_path)\n",
    "    with open(opentargets_reactome_metadata_path, \"rb\") as file:\n",
    "        opentargets_reactome_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Gene Ontology from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentargets_go_path = os.path.join(base_dir, \"examples\", \"data\", \"example_ot_go.pkl\")\n",
    "opentargets_go_metadata_path = os.path.join(\n",
    "    base_dir, \"examples\", \"data\", \"example_ot_go_metadata.pkl\"\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(opentargets_go_path):\n",
    "    opentargets_go_df, opentargets_go_metadata = opentargets.get_gene_go_process(\n",
    "        bridgedb_df=bridgedb_df\n",
    "    )\n",
    "    opentargets_go_df.to_pickle(opentargets_go_path)\n",
    "    with open(opentargets_go_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(opentargets_go_metadata, file)\n",
    "else:\n",
    "    opentargets_go_df = pd.read_pickle(opentargets_go_path)\n",
    "    with open(opentargets_go_metadata_path, \"rb\") as file:\n",
    "        opentargets_go_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compound annotation\n",
    "### 5.1. Compound annotation from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentargets_gene_path = os.path.join(base_dir, \"examples\", \"data\", \"example_ot_gene_cmpd.pkl\")\n",
    "opentargets_gene_metadata_path = os.path.join(\n",
    "    base_dir, \"examples\", \"data\", \"example_ot_gene_cmpd_metadata.pkl\"\n",
    ")\n",
    "\n",
    "\n",
    "if not os.path.exists(opentargets_gene_path):\n",
    "    opentargets_compound_df, opentargets_compound_metadata = (\n",
    "        opentargets.get_gene_compound_interactions(bridgedb_df=bridgedb_df)\n",
    "    )\n",
    "    opentargets_compound_df.to_pickle(opentargets_gene_path)\n",
    "    with open(opentargets_gene_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(opentargets_compound_metadata, file)\n",
    "\n",
    "else:\n",
    "    opentargets_compound_df = pd.read_pickle(opentargets_gene_path)\n",
    "    with open(opentargets_gene_metadata_path, \"rb\") as file:\n",
    "        opentargets_compound_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Screening results of compounds on proteins encoded by genes annotation by PubChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubchem_path = os.path.join(base_dir, \"examples\", \"data\", \"example_pubchem.pkl\")\n",
    "pubchem_metadata_path = os.path.join(base_dir, \"examples\", \"data\", \"example_pubchem_metadata.pkl\")\n",
    "\n",
    "if not os.path.exists(pubchem_path):\n",
    "    pubchem_assay_df, pubchem_assay_metadata = pubchem.get_protein_compound_screened(\n",
    "        bridgedb_df=bridgedb_df\n",
    "    )\n",
    "    pubchem_assay_df.to_pickle(pubchem_path)\n",
    "    with open(pubchem_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(pubchem_assay_metadata, file)\n",
    "\n",
    "else:\n",
    "    pubchem_assay_df = pd.read_pickle(pubchem_path)\n",
    "    with open(pubchem_metadata_path, \"rb\") as file:\n",
    "        pubchem_assay_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Membrane transport annotations\n",
    "### 6.1 Transporter inhibitor annotation from MolMeDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molmedb_path = os.path.join(base_dir, \"examples\", \"data\", \"example_molmedb_gene_cmpd.pkl\")\n",
    "molmedb_metadata_path = os.path.join(\n",
    "    base_dir, \"examples\", \"data\", \"example_molmedb_gene_cmpd_metadata.pkl\"\n",
    ")\n",
    "\n",
    "if not os.path.exists(molmedb_path):\n",
    "    inhibitor_df, inhibitor_metadata = molmedb.get_gene_compound_inhibitor(bridgedb_df=bridgedb_df)\n",
    "    inhibitor_df.to_pickle(molmedb_path)\n",
    "    with open(molmedb_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(inhibitor_metadata, file)\n",
    "else:\n",
    "    inhibitor_df = pd.read_pickle(molmedb_path)\n",
    "    with open(molmedb_metadata_path, \"rb\") as file:\n",
    "        inhibitor_metadata = pickle.load(file)\n",
    "inhibitor_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Protein-Protein Interactions\n",
    "\n",
    "### 7.1. Protein-Protein Interactions from STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm examples/data/example_string*\n",
    "string_path = os.path.join(base_dir, \"examples\", \"data\", \"example_string.pkl\")\n",
    "string_metadata_path = os.path.join(base_dir, \"examples\", \"data\", \"example_string_metadata.pkl\")\n",
    "\n",
    "if not os.path.exists(string_path):\n",
    "    ppi_df, ppi_metadata = stringdb.get_ppi(bridgedb_df=bridgedb_df)\n",
    "    ppi_df.to_pickle(string_path)\n",
    "    with open(string_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(ppi_metadata, file)\n",
    "else:\n",
    "    ppi_df = pd.read_pickle(string_path)\n",
    "    with open(string_metadata_path, \"rb\") as file:\n",
    "        ppi_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_df.StringDB_ppi[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Graph generation \n",
    "\n",
    "### 8.1. Combine all data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combine_sources(\n",
    "    bridgedb_df,\n",
    "    [\n",
    "        bgee_df,\n",
    "        # disgenet_df,\n",
    "        minerva_df,\n",
    "        wikipathways_df,\n",
    "        opentargets_reactome_df,\n",
    "        opentargets_go_df,\n",
    "        opentargets_compound_df,\n",
    "        inhibitor_df,\n",
    "        pubchem_assay_df,\n",
    "        ppi_df,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_pickle(os.path.join(base_dir, \"examples\", \"data\", \"combined_df.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code chunk shuffles the DisGeNET-queried data before serializing the graphs and displaying them, as it is not open access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the rows\n",
    "import numpy as np\n",
    "\n",
    "combined_df[\"DISGENET_diseases\"] = combined_df[\"DISGENET_diseases\"].apply(np.random.permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metadata = create_or_append_to_metadata(\n",
    "    bridgedb_metadata,\n",
    "    [\n",
    "        bgee_metadata,\n",
    "        # disgenet_metadata,\n",
    "        # opentargets_metadata,\n",
    "        opentargets_compound_metadata,\n",
    "        inhibitor_metadata,\n",
    "        pubchem_assay_metadata,\n",
    "        ppi_metadata,\n",
    "        wikipathways_metadata,\n",
    "        minerva_metadata,\n",
    "        opentargets_reactome_metadata,\n",
    "        opentargets_go_metadata,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export the combined (meta) data in pickle format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_pickle(os.path.join(base_dir, \"examples\", \"data\", \"example_df_shuffled.pkl\"))\n",
    "with open(\"example_metadata.pkl\", \"wb\") as out:\n",
    "    pickle.dump(combined_metadata, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Create a graph from the annotated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pygraph = generator.save_graph(\n",
    "    combined_df=combined_df,\n",
    "    combined_metadata=combined_metadata,\n",
    "    disease_compound=opentargets_df,\n",
    "    graph_name=\"examples\",\n",
    "    graph_dir=\"./data\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3. Cytoscape\n",
    "Make sure that the Cytoscape is open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyBiodatafuse.graph import cytoscape\n",
    "\n",
    "# cytoscape.load_graph(pygraph, network_name=\"Test network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4. Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyBiodatafuse.graph import neo4j\n",
    "\n",
    "neo4j.save_graph_to_graphml(pygraph, \"networkx_graph_test.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Steps to load the graph in Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add `.graphml` file in **import** subfolder of the DBMS folder\n",
    "- Install apoc plugin\n",
    "- Create `apoc.conf` file:\n",
    "    ```\n",
    "    apoc.trigger.enabled=true\n",
    "    apoc.import.file.enabled=true\n",
    "    apoc.export.file.enabled=true\n",
    "    apoc.import.file.use_neo4j_config=true\n",
    "    ```\n",
    "- Add `apoc.conf` file to **conf** subfolder of the DBMS folder\n",
    "- Open Neo4j Browser\n",
    "- (Optionl, only run if you have imported a graph  before) Remove all the nodes before importing `.graphml` file\n",
    "\n",
    "    ```MATCH (n) DETACH DELETE n```\n",
    "\n",
    "- Import `.graphml` file\n",
    "\n",
    "    ```call apoc.import.graphml('file:///networkx_graph_test.graphml',{readLabels:TRUE})```\n",
    "\n",
    "- Add indexes after importing the graph for improving the performance of queries\n",
    "\n",
    "    ```\n",
    "    create index Gene for (n:Gene) on (n.node_type)\n",
    "    create index Pathway for (n:Pathway) on (n.node_type)\n",
    "    create index `Biological Process` for (n:`Biological Process`) on (n.node_type)\n",
    "    create index `Molecular Function` for (n:`Molecular Function`) on (n.node_type)\n",
    "    create index `Cellular Component` for (n:`Cellular Component`) on (n.node_type)\n",
    "    create index Disease for (n:Disease) on (n.node_type)\n",
    "    create index Compound for (n:Compound) on (n.node_type)\n",
    "    create index `Side Effect` for (n:`Side Effect`) on (n.node_type)\n",
    "    ```\n",
    "    \n",
    "\n",
    "- Count the number of each node type\n",
    "    - total (```MATCH (n) RETURN count(n)```) \n",
    "        - Gene (```MATCH (n:Gene) RETURN count(n)```)\n",
    "        - Pathway (```MATCH (n:Pathway) RETURN count(n)```)\n",
    "            - WikiPathways (```MATCH (n:Pathway {source: \"WikiPathways\"}) RETURN count(n)```) \n",
    "            - OpenTargets, Reactome (```MATCH (n:Pathway {source: \"OpenTargets\"}) RETURN count(n)```) \n",
    "            - MINERVA (```MATCH (n:Pathway {source: \"MINERVA\"}) RETURN count(n)```) \n",
    "        - Biological Process (```MATCH (n:`Biological Process`) RETURN count(n)```) \n",
    "        - Molecular Function (```MATCH (n:`Molecular Function`) RETURN count(n)```) \n",
    "        - Cellular Component (```MATCH (n:`Cellular Component`) RETURN count(n)```) \n",
    "        - Disease (```MATCH (n:Disease) RETURN count(n)```) \n",
    "        - Compound (```MATCH (n:Compound) RETURN count(n)```)\n",
    "        - Side Effect (```MATCH (n:`Side Effect`) RETURN count(n)```) \n",
    "- Count the number of each edge type\n",
    "    - total (```MATCH ()-[r]->() RETURN count(r)```) \n",
    "        - interacts_with (```MATCH ()-[r:interacts_with]->() RETURN count(r)```) \n",
    "        - part_of (```MATCH ()-[r:part_of]->() RETURN count(r)```) \n",
    "            - WikiPathways (```MATCH ()-[r:part_of {source: \"WikiPathways\"}]->() RETURN count(r)```) \n",
    "            - OpenTargets, Reactome (```MATCH ()-[r:part_of {source: \"OpenTargets\"}]->() RETURN count(r)```) \n",
    "            - MINERVA (```MATCH ()-[r:part_of {source: \"MINERVA\"}]->() RETURN count(r)```) \n",
    "        - activates (```MATCH ()-[r:activates]->() RETURN count(r)```) \n",
    "        - treats (```MATCH ()-[r:treats]->() RETURN count(r)```) \n",
    "        - has_side_effect (```MATCH ()-[r:has_side_effect]->() RETURN count(r)```) \n",
    "        - inhibits (```MATCH ()-[r:inhibits]->() RETURN count(r)```) = 71\n",
    "        - associated_with (```MATCH ()-[r:associated_with]->() RETURN count(r)```) \n",
    "\n",
    "- Export the graph as a `.csv` file\n",
    "\n",
    "    ```call apoc.export.csv.all(\"networkx_graph_test.csv\",{})```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5. RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a BDFGraph\n",
    "bdf = BDFGraph(\n",
    "    base_uri=\"https://biodatafuse.org/example/\",\n",
    "    version_iri=\"https://biodatafuse.org/example/test.owl\",\n",
    "    orcid=\"https://orcid.org/0000-0002-4166-7093\",\n",
    "    author=\"Javier Millan Acosta\",\n",
    ")\n",
    "\n",
    "bdf.generate_rdf(combined_df, combined_metadata)  # Generate the RDF from the (meta)data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf.serialize(\n",
    "    os.path.join(base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_graph.ttl\"),\n",
    "    format=\"ttl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bridgedb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.5.1. Generate prefixes SHACL\n",
    "\n",
    "SHACL graphs defining namespaces and prefixes can be loaded into SPARQL endpoints to avoid having to declare prefixes in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use without parameters (defaults, does not save file)\n",
    "bdf.shacl_prefixes()\n",
    "# or Use with parameters\n",
    "bdf.shacl_prefixes(\n",
    "    path=os.path.join(base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_prefixes.ttl\"),\n",
    "    namespaces=None,  # Optional, add more namespaces with a dictionary of {prefix:namespace,}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.5.2. Use [`shexer`](https://github.com/DaniFdezAlvarez/shexer/) to retrieve the RDF shapes\n",
    "\n",
    "The `shexer` library is used to retrieve the shapes of the graph in SHACL (https://www.w3.org/TR/shacl/) and ShEx (https://shex.io/shex-semantics/).\n",
    "\n",
    "- **SHACL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use without parameters (defaults)\n",
    "# bdf.shacl()\n",
    "\n",
    "# Or use with parameters\n",
    "bdf.shacl(\n",
    "    path=os.path.join(\n",
    "        base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shacl.ttl\"\n",
    "    ),  # Set a path for TTL serialization\n",
    "    threshold=0.001,\n",
    "    uml_figure_path=os.path.join(\n",
    "        base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shacl.png\"\n",
    "    ),  # Set a path for diagram\n",
    ")\n",
    "\n",
    "# Display the UML figure\n",
    "display(\n",
    "    Image(\n",
    "        os.path.join(\n",
    "            base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shacl.png\"\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ShEx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use without parameters (defaults)\n",
    "# bdf.shex()\n",
    "\n",
    "# Or use with parameters\n",
    "bdf.shex(\n",
    "    path=os.path.join(\n",
    "        base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shex.ttl\"\n",
    "    ),  # Set a path for TTL serialization\n",
    "    threshold=0.001,\n",
    "    uml_figure_path=os.path.join(\n",
    "        base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shex.png\"\n",
    "    ),  # Set a path for diagram\n",
    ")\n",
    "\n",
    "# Display the UML figure\n",
    "display(\n",
    "    Image(\n",
    "        os.path.join(base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shex.png\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elapsed time for the workflow, if ran in block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours = elapsed_time // 3600\n",
    "minutes = (elapsed_time % 3600) // 60\n",
    "seconds = elapsed_time % 60\n",
    "milliseconds = (elapsed_time % 1) * 1000\n",
    "\n",
    "# Display elapsed time in h:m:s:ms\n",
    "print(f\"Elapsed Time: {int(hours)}h {int(minutes)}m {int(seconds)}s {int(milliseconds)}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.5.3 Set up a virtuoso endpoint to query the RDF graph\n",
    "\n",
    "[This repository](https://github.com/jmillanacosta/fast-virtuoso) provides a quick way to set up a local Virtuoso endpoint using its docker image.\n",
    "\n",
    "Upload the prefixes (`bdf.shacl_prefixes(path=\"your/path\")`) and the BDF graph generated above (`bdf.serialize(\"your/path\", format=\"ttl\")`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to send some sample SELECT queries and return the response in a pandas DataFrame\n",
    "import requests\n",
    "\n",
    "\n",
    "def send_sparql_query(query, endpoint=\"http://localhost:8899/sparql\", format=\"text/csv\"):\n",
    "    headers = {\"Accept\": format}\n",
    "    params = {\"query\": query}\n",
    "    response = requests.get(endpoint, headers=headers, params=params)\n",
    "\n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        if format == \"text/csv\":\n",
    "            # Convert CSV response to pandas DataFrame\n",
    "            from io import StringIO\n",
    "\n",
    "            csv_data = StringIO(response.text)\n",
    "            return pd.read_csv(csv_data)\n",
    "        else:\n",
    "            return response.text  # For other formats if needed\n",
    "    else:\n",
    "        raise Exception(f\"Query failed with status code {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import RDF, RDFS, SH, Graph\n",
    "\n",
    "# Parse the query graph\n",
    "# Load the graph\n",
    "query_g = Graph()\n",
    "with open(\"examples/SPARQL/queries.ttl\", \"r\") as f:\n",
    "    query_g.parse(f, format=\"turtle\")\n",
    "\n",
    "# Extract queries and comments into a list of dictionaries\n",
    "queries_list = []\n",
    "for s in query_g.subjects(RDF.type, SH.SPARQLSelectExecutable):\n",
    "    query_text = query_g.value(s, SH.select)\n",
    "    comment = query_g.value(s, RDFS.comment)\n",
    "\n",
    "    if query_text and comment:\n",
    "        # Append a dictionary for each query and its comment\n",
    "        queries_list.append({\"comment\": comment.value, \"query\": query_text.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_0 = send_sparql_query(queries_list[0][\"query\"])\n",
    "print(queries_list[0][\"comment\"])\n",
    "print(queries_list[0][\"query\"])\n",
    "query_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_3 = send_sparql_query(queries_list[3][\"query\"])\n",
    "print(queries_list[3][\"query\"])\n",
    "print(queries_list[3][\"comment\"])\n",
    "query_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
