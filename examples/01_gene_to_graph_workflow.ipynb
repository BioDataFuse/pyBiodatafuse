{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gene-to-graph workflow\n",
    "\n",
    "This notebook showcases the steps to generate the BioDataFuse data and graph serializations from a list of genes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/yojana/Documents/GitHub/pyBiodatafuse\n"
     ]
    }
   ],
   "source": [
    "# Setting up the working directory\n",
    "import os\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "os.chdir(os.path.join(f\"{current_dir}\", \"..\"))\n",
    "\n",
    "# Set the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current directory:\", current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pybiodatafuse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import modules\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from pyBiodatafuse import id_mapper\n",
    "from pyBiodatafuse.annotators import (\n",
    "    bgee,\n",
    "    disgenet,\n",
    "    minerva,\n",
    "    molmedb,\n",
    "    opentargets,\n",
    "    pubchem,\n",
    "    stringdb,\n",
    "    wikipathways,\n",
    ")\n",
    "from pyBiodatafuse.constants import DISGENET_DISEASE_COL\n",
    "from pyBiodatafuse.graph import saver\n",
    "from pyBiodatafuse.graph.rdf import BDFGraph\n",
    "from pyBiodatafuse.utils import (\n",
    "    combine_sources,\n",
    "    create_harmonized_input_file,\n",
    "    create_or_append_to_metadata,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entity resolution with BridgeDB\n",
    "\n",
    "The first step is to input the list of genes to query and retrieve their protein target and synonym identifiers using BridgeDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the input list and convert it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAGRN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALG14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALG2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHD8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identifier\n",
       "0      AAGRN\n",
       "1      ALG14\n",
       "2       ALG2\n",
       "3       CHAT\n",
       "4       CHD8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_of_interest = \"\"\"AAGRN\n",
    "ALG14\n",
    "ALG2\n",
    "CHAT\n",
    "CHD8\n",
    "CHRNA1\n",
    "CHRNB1\n",
    "CHRND\n",
    "CHRNE\n",
    "CHRNG\n",
    "COL13A1\n",
    "COLQ\n",
    "DOK7\n",
    "DPAGT1\n",
    "GFPT1\n",
    "GMPPB\n",
    "LAMA5\n",
    "LAMB2\n",
    "LRP4\n",
    "MUSK\n",
    "MYO9A\n",
    "PLEC\n",
    "PREPL\n",
    "PURA\n",
    "RAPSN\n",
    "RPH3A\n",
    "SCN4A\n",
    "SLC18A3\n",
    "SLC25A1\n",
    "SLC5A7\n",
    "SNAP25\n",
    "SYT2\n",
    "TOR1AIP1\n",
    "UNC13A\n",
    "VAMP1\n",
    "DMD\"\"\"\n",
    "\n",
    "gene_list = genes_of_interest.split(\"\\n\")\n",
    "data_input = pd.DataFrame(gene_list, columns=[\"identifier\"])\n",
    "data_input.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Query BridgeDB\n",
    "The results will be stored in the following directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(os.getcwd())  # Ensures an absolute path\n",
    "DATA_DIR = os.path.join(base_dir, \"examples\", \"data\")\n",
    "EXAMPLE_DIR = os.path.join(base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\")\n",
    "os.makedirs(DATA_DIR, exist_ok=True)  # TODO paths\n",
    "os.makedirs(EXAMPLE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = f\"{EXAMPLE_DIR}/example_gene_list.pkl\"\n",
    "metadata_path = f\"{EXAMPLE_DIR}/example_gene_list_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(pickle_path):\n",
    "    bridgedb_df, bridgedb_metadata = id_mapper.bridgedb_xref(\n",
    "        identifiers=data_input,\n",
    "        input_species=\"Human\",\n",
    "        input_datasource=\"HGNC\",\n",
    "        output_datasource=\"All\",\n",
    "    )\n",
    "    bridgedb_df.to_pickle(pickle_path)\n",
    "    with open(metadata_path, \"wb\") as file:\n",
    "        pickle.dump(bridgedb_metadata, file)\n",
    "else:\n",
    "    bridgedb_df = pd.read_pickle(pickle_path)\n",
    "    with open(metadata_path, \"rb\") as file:\n",
    "        bridgedb_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can also skip `input_datasource` for most identifier types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>identifier.source</th>\n",
       "      <th>target</th>\n",
       "      <th>target.source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>1553954_at</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>Q96F25</td>\n",
       "      <td>Uniprot-TrEMBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>GO:0016021</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>GO:0016020</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>A_23_P257423</td>\n",
       "      <td>Agilent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>DMD</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>4004045</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4693</th>\n",
       "      <td>DMD</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>4004287</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4694</th>\n",
       "      <td>DMD</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>4004286</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>DMD</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>4004285</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>DMD</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>GO:0030036</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4697 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     identifier identifier.source        target   target.source\n",
       "0         ALG14              HGNC    1553954_at            Affy\n",
       "1         ALG14              HGNC        Q96F25  Uniprot-TrEMBL\n",
       "2         ALG14              HGNC    GO:0016021   Gene Ontology\n",
       "3         ALG14              HGNC    GO:0016020   Gene Ontology\n",
       "4         ALG14              HGNC  A_23_P257423         Agilent\n",
       "...         ...               ...           ...             ...\n",
       "4692        DMD              HGNC       4004045            Affy\n",
       "4693        DMD              HGNC       4004287            Affy\n",
       "4694        DMD              HGNC       4004286            Affy\n",
       "4695        DMD              HGNC       4004285            Affy\n",
       "4696        DMD              HGNC    GO:0030036   Gene Ontology\n",
       "\n",
       "[4697 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bridgedb_df_test, bridgedb_metadata_test = id_mapper.bridgedb_xref(\n",
    "    identifiers=data_input,\n",
    "    input_species=\"Human\",\n",
    "    # input_datasource=\"HGNC\", # Commented out\n",
    "    output_datasource=\"All\",\n",
    ")\n",
    "bridgedb_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes with mapping in BridgeDb: 35\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>identifier.source</th>\n",
       "      <th>target</th>\n",
       "      <th>target.source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>1553954_at</td>\n",
       "      <td>Affy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>Q96F25</td>\n",
       "      <td>Uniprot-TrEMBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>GO:0016021</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>GO:0016020</td>\n",
       "      <td>Gene Ontology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALG14</td>\n",
       "      <td>HGNC</td>\n",
       "      <td>A_23_P257423</td>\n",
       "      <td>Agilent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  identifier identifier.source        target   target.source\n",
       "0      ALG14              HGNC    1553954_at            Affy\n",
       "1      ALG14              HGNC        Q96F25  Uniprot-TrEMBL\n",
       "2      ALG14              HGNC    GO:0016021   Gene Ontology\n",
       "3      ALG14              HGNC    GO:0016020   Gene Ontology\n",
       "4      ALG14              HGNC  A_23_P257423         Agilent"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of genes with mapping in BridgeDb:\", len(bridgedb_df[\"identifier\"].unique()))\n",
    "bridgedb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gene expression\n",
    "### 2.1. Gene expression from Bgee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Querying Bgee:   2%|▏         | 4/169 [03:39<2:31:27, 55.08s/it]"
     ]
    }
   ],
   "source": [
    "bgee_path = f\"{EXAMPLE_DIR}/example_bgee.pkl\"\n",
    "bgee_metadata_path = f\"{EXAMPLE_DIR}/example_bgee_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(bgee_path):\n",
    "    bgee_df, bgee_metadata = bgee.get_gene_expression(bridgedb_df=bridgedb_df)\n",
    "    bgee_df.to_pickle(bgee_path)\n",
    "    with open(bgee_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(bgee_metadata, file)\n",
    "else:\n",
    "    bgee_df = pd.read_pickle(bgee_path)\n",
    "    with open(bgee_metadata_path, \"rb\") as file:\n",
    "        bgee_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Disease annotation\n",
    "### 3.1. Gene to disease annotation with DisGeNET"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import dotenv\n",
    "disgenet_api_key = dotenv.dotenv_values(\".env\")[\"DISGENET_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "disgenet_path = f\"{EXAMPLE_DIR}/example_disgenet.pkl\"\n",
    "disgenet_metadata_path = f\"{EXAMPLE_DIR}/example_disgenet_metadata.pkl\"\n",
    "\n",
    "disgenet_api_key = \"PASTE_YOUR_DISGENET_API_KEY_HERE\"\n",
    "\n",
    "if not os.path.exists(disgenet_path):\n",
    "    disgenet_df, disgenet_metadata = disgenet.get_gene_disease(\n",
    "        api_key=disgenet_api_key, bridgedb_df=bridgedb_df\n",
    "    )\n",
    "\n",
    "    disgenet_df.to_pickle(disgenet_path)\n",
    "    with open(disgenet_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(disgenet_metadata, file)\n",
    "else:\n",
    "    disgenet_df = pd.read_pickle(disgenet_path)\n",
    "    with open(disgenet_metadata_path, \"rb\") as file:\n",
    "        disgenet_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Disease to compound annotation from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>identifier.source</th>\n",
       "      <th>target</th>\n",
       "      <th>target.source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UMLS_C5680989</td>\n",
       "      <td>UMLS</td>\n",
       "      <td>EFO_0700079</td>\n",
       "      <td>EFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UMLS_C0017605</td>\n",
       "      <td>UMLS</td>\n",
       "      <td>EFO_1001506</td>\n",
       "      <td>EFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UMLS_C0751884</td>\n",
       "      <td>UMLS</td>\n",
       "      <td>EFO_0700127</td>\n",
       "      <td>EFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UMLS_C0011581</td>\n",
       "      <td>UMLS</td>\n",
       "      <td>EFO_0004257</td>\n",
       "      <td>EFO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UMLS_C0011581</td>\n",
       "      <td>UMLS</td>\n",
       "      <td>EFO_0008623</td>\n",
       "      <td>EFO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier identifier.source       target target.source\n",
       "0  UMLS_C5680989              UMLS  EFO_0700079           EFO\n",
       "2  UMLS_C0017605              UMLS  EFO_1001506           EFO\n",
       "3  UMLS_C0751884              UMLS  EFO_0700127           EFO\n",
       "4  UMLS_C0011581              UMLS  EFO_0004257           EFO\n",
       "5  UMLS_C0011581              UMLS  EFO_0008623           EFO"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the input to use DISGENET output as seed for OpenTargets\n",
    "disease_mapping_df = create_harmonized_input_file(disgenet_df, DISGENET_DISEASE_COL, \"EFO\", \"UMLS\")\n",
    "disease_mapping_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentarget_path = f\"{EXAMPLE_DIR}/example_opentarget_cmpd.pkl\"\n",
    "opentarget_metadata_path = f\"{EXAMPLE_DIR}/example_opentarget_cmpd_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(opentarget_path):\n",
    "    opentargets_df, opentargets_metadata = opentargets.get_disease_compound_interactions(\n",
    "        disease_mapping_df\n",
    "    )\n",
    "    opentargets_df.to_pickle(opentarget_path)\n",
    "    with open(opentarget_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(opentargets_metadata, file)\n",
    "else:\n",
    "    opentargets_df = pd.read_pickle(opentarget_path)\n",
    "    with open(opentarget_metadata_path, \"rb\") as file:\n",
    "        opentargets_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pathways and Gene Ontology terms\n",
    "### 4.1. Pathways from MINERVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "minerva_path = f\"{EXAMPLE_DIR}/example_minerva.pkl\"\n",
    "minerva_metadata_path = f\"{EXAMPLE_DIR}/example_minerva_metadata.pkl\"\n",
    "\n",
    "\n",
    "if not os.path.exists(minerva_path):\n",
    "    minerva_df, minerva_metadata = minerva.get_gene_minerva_pathways(\n",
    "        bridgedb_df, map_name=\"COVID19 Disease Map\"\n",
    "    )\n",
    "    minerva_df.to_pickle(minerva_path)\n",
    "    with open(minerva_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(minerva_metadata, file)\n",
    "\n",
    "else:\n",
    "    minerva_df = pd.read_pickle(minerva_path)\n",
    "    with open(minerva_metadata_path, \"rb\") as file:\n",
    "        minerva_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Pathways from WikiPathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipathways_path = f\"{EXAMPLE_DIR}/example_wikipathway.pkl\"\n",
    "wikipathways_metadata_path = f\"{EXAMPLE_DIR}/example_wikipathway_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(wikipathways_path):\n",
    "    wikipathways_df, wikipathways_metadata = wikipathways.get_gene_wikipathways(\n",
    "        bridgedb_df=bridgedb_df\n",
    "    )\n",
    "    wikipathways_df.to_pickle(wikipathways_path)\n",
    "    with open(wikipathways_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(wikipathways_metadata, file)\n",
    "\n",
    "else:\n",
    "    wikipathways_df = pd.read_pickle(wikipathways_path)\n",
    "    with open(wikipathways_metadata_path, \"rb\") as file:\n",
    "        wikipathways_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Reactome pathways from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentargets_reactome_path = f\"{EXAMPLE_DIR}/example_ot_reactome.pkl\"\n",
    "opentargets_reactome_metadata_path = f\"{EXAMPLE_DIR}/example_ot_reactome_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(opentargets_reactome_path):\n",
    "    opentargets_reactome_df, opentargets_reactome_metadata = opentargets.get_gene_reactome_pathways(\n",
    "        bridgedb_df=bridgedb_df\n",
    "    )\n",
    "    opentargets_reactome_df.to_pickle(opentargets_reactome_path)\n",
    "    with open(opentargets_reactome_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(opentargets_reactome_metadata, file)\n",
    "else:\n",
    "    opentargets_reactome_df = pd.read_pickle(opentargets_reactome_path)\n",
    "    with open(opentargets_reactome_metadata_path, \"rb\") as file:\n",
    "        opentargets_reactome_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Gene Ontology from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentargets_go_path = f\"{EXAMPLE_DIR}/example_ot_go.pkl\"\n",
    "opentargets_go_metadata_path = f\"{EXAMPLE_DIR}/example_ot_go_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(opentargets_go_path):\n",
    "    opentargets_go_df, opentargets_go_metadata = opentargets.get_gene_go_process(\n",
    "        bridgedb_df=bridgedb_df\n",
    "    )\n",
    "    opentargets_go_df.to_pickle(opentargets_go_path)\n",
    "    with open(opentargets_go_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(opentargets_go_metadata, file)\n",
    "else:\n",
    "    opentargets_go_df = pd.read_pickle(opentargets_go_path)\n",
    "    with open(opentargets_go_metadata_path, \"rb\") as file:\n",
    "        opentargets_go_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compound annotation\n",
    "### 5.1. Compound annotation from OpenTargets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opentargets_gene_path = f\"{EXAMPLE_DIR}/example_ot_gene_cmpd.pkl\"\n",
    "opentargets_gene_metadata_path = f\"{EXAMPLE_DIR}/example_ot_gene_cmpd_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(opentargets_gene_path):\n",
    "    opentargets_compound_df, opentargets_compound_metadata = (\n",
    "        opentargets.get_gene_compound_interactions(bridgedb_df=bridgedb_df)\n",
    "    )\n",
    "    opentargets_compound_df.to_pickle(opentargets_gene_path)\n",
    "    with open(opentargets_gene_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(opentargets_compound_metadata, file)\n",
    "\n",
    "else:\n",
    "    opentargets_compound_df = pd.read_pickle(opentargets_gene_path)\n",
    "    with open(opentargets_gene_metadata_path, \"rb\") as file:\n",
    "        opentargets_compound_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Screening results of compounds on proteins encoded by genes annotation by PubChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubchem_path = f\"{EXAMPLE_DIR}/example_pubchem.pkl\"\n",
    "pubchem_metadata_path = f\"{EXAMPLE_DIR}/example_pubchem_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(pubchem_path):\n",
    "    pubchem_assay_df, pubchem_assay_metadata = pubchem.get_protein_compound_screened(\n",
    "        bridgedb_df=bridgedb_df\n",
    "    )\n",
    "    pubchem_assay_df.to_pickle(pubchem_path)\n",
    "    with open(pubchem_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(pubchem_assay_metadata, file)\n",
    "\n",
    "else:\n",
    "    pubchem_assay_df = pd.read_pickle(pubchem_path)\n",
    "    with open(pubchem_metadata_path, \"rb\") as file:\n",
    "        pubchem_assay_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Membrane transport annotations\n",
    "### 6.1 Transporter inhibitor annotation from MolMeDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "molmedb_path = f\"{EXAMPLE_DIR}/example_molmedb_gene_cmpd.pkl\"\n",
    "molmedb_metadata_path = f\"{EXAMPLE_DIR}/example_molmedb_gene_cmpd_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(molmedb_path):\n",
    "    inhibitor_df, inhibitor_metadata = molmedb.get_gene_compound_inhibitor(bridgedb_df=bridgedb_df)\n",
    "    inhibitor_df.to_pickle(molmedb_path)\n",
    "    with open(molmedb_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(inhibitor_metadata, file)\n",
    "else:\n",
    "    inhibitor_df = pd.read_pickle(molmedb_path)\n",
    "    with open(molmedb_metadata_path, \"rb\") as file:\n",
    "        inhibitor_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Protein-Protein Interactions\n",
    "\n",
    "### 7.1. Protein-Protein Interactions from STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_path = f\"{EXAMPLE_DIR}/example_string.pkl\"\n",
    "string_metadata_path = f\"{EXAMPLE_DIR}/example_string_metadata.pkl\"\n",
    "\n",
    "if not os.path.exists(string_path):\n",
    "    ppi_df, ppi_metadata = stringdb.get_ppi(bridgedb_df=bridgedb_df)\n",
    "    ppi_df.to_pickle(string_path)\n",
    "    with open(string_metadata_path, \"wb\") as file:\n",
    "        pickle.dump(ppi_metadata, file)\n",
    "else:\n",
    "    ppi_df = pd.read_pickle(string_path)\n",
    "    with open(string_metadata_path, \"rb\") as file:\n",
    "        ppi_metadata = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Graph generation \n",
    "\n",
    "### 8.1. Combine all data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combine_sources(\n",
    "    bridgedb_df,\n",
    "    [\n",
    "        bgee_df,\n",
    "        disgenet_df,\n",
    "        minerva_df,\n",
    "        wikipathways_df,\n",
    "        opentargets_reactome_df,\n",
    "        opentargets_go_df,\n",
    "        opentargets_compound_df,\n",
    "        inhibitor_df,\n",
    "        pubchem_assay_df,\n",
    "        ppi_df,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_pickle(f\"{EXAMPLE_DIR}/combined_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code chunk shuffles the DisGeNET-queried data before serializing the graphs and displaying them, as it is not open access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling the rows\n",
    "combined_df[\"DISGENET_diseases\"] = combined_df[\"DISGENET_diseases\"].apply(np.random.permutation)\n",
    "\n",
    "combined_metadata = create_or_append_to_metadata(\n",
    "    bridgedb_metadata,\n",
    "    [\n",
    "        bgee_metadata,\n",
    "        disgenet_metadata,\n",
    "        opentargets_metadata,\n",
    "        opentargets_compound_metadata,\n",
    "        inhibitor_metadata,\n",
    "        pubchem_assay_metadata,\n",
    "        ppi_metadata,\n",
    "        wikipathways_metadata,\n",
    "        minerva_metadata,\n",
    "        opentargets_reactome_metadata,\n",
    "        opentargets_go_metadata,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export the combined (meta) data in pickle format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_pickle(f\"{EXAMPLE_DIR}/example_df_shuffled.pkl\")\n",
    "with open(f\"{EXAMPLE_DIR}/example_metadata.pkl\", \"wb\") as out:\n",
    "    pickle.dump(combined_metadata, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2. Create a graph from the annotated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combined DataFrame saved in /Users/yojana/Documents/GitHub/pyBiodatafuse/examples/data/gene_to_graph_workflow/gene_examples_df.pkl\n",
      "Metadata saved in /Users/yojana/Documents/GitHub/pyBiodatafuse/examples/data/gene_to_graph_workflow/gene_examples_metadata.pkl\n",
      "Building graph: 100%|██████████| 35/35 [00:00<00:00, 617.82it/s]\n",
      "Building graph: 100%|██████████| 35/35 [00:00<00:00, 4886.19it/s]\n",
      "Graph is built successfully\n",
      "Graph saved in /Users/yojana/Documents/GitHub/pyBiodatafuse/examples/data/gene_to_graph_workflow/gene_examples_graph.pkl and /Users/yojana/Documents/GitHub/pyBiodatafuse/examples/data/gene_to_graph_workflow/gene_examples_graph.gml\n",
      "Graph saved in /Users/yojana/Documents/GitHub/pyBiodatafuse/examples/data/gene_to_graph_workflow/gene_examples_graph.edgelist\n"
     ]
    }
   ],
   "source": [
    "pygraph = saver.save_graph(\n",
    "    combined_df=combined_df,\n",
    "    combined_metadata=combined_metadata,\n",
    "    disease_compound=opentargets_df,\n",
    "    graph_name=\"gene_examples\",\n",
    "    graph_dir=EXAMPLE_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMLS:C0000786\n",
      "UMLS:C0001125\n",
      "UMLS:C0003089\n",
      "UMLS:C0003469\n",
      "UMLS:C0003873\n",
      "UMLS:C0004352\n",
      "UMLS:C0006142\n",
      "UMLS:C0006663\n",
      "UMLS:C0007193\n",
      "UMLS:C0007194\n",
      "UMLS:C0008073\n",
      "UMLS:C0009402\n",
      "UMLS:C0009404\n",
      "UMLS:C0011581\n",
      "UMLS:C0012242\n",
      "UMLS:C0013080\n",
      "UMLS:C0013404\n",
      "UMLS:C0014544\n",
      "UMLS:C0014547\n",
      "UMLS:C0014549\n",
      "UMLS:C0016059\n",
      "UMLS:C0017668\n",
      "UMLS:C0018800\n",
      "UMLS:C0018817\n",
      "UMLS:C0022658\n",
      "UMLS:C0023269\n",
      "UMLS:C0025281\n",
      "UMLS:C0025322\n",
      "UMLS:C0026848\n",
      "UMLS:C0026896\n",
      "UMLS:C0027540\n",
      "UMLS:C0027726\n",
      "UMLS:C0028754\n",
      "UMLS:C0029516\n",
      "UMLS:C0030193\n",
      "UMLS:C0031117\n",
      "UMLS:C0032227\n",
      "UMLS:C0032290\n",
      "UMLS:C0032460\n",
      "UMLS:C0033141\n",
      "UMLS:C0035126\n",
      "UMLS:C0035229\n",
      "UMLS:C0035309\n",
      "UMLS:C0035410\n",
      "UMLS:C0036439\n",
      "UMLS:C0036529\n",
      "UMLS:C0036572\n",
      "UMLS:C0037772\n",
      "UMLS:C0038220\n",
      "UMLS:C0038356\n",
      "UMLS:C0041696\n",
      "UMLS:C0206656\n",
      "UMLS:C0264886\n",
      "UMLS:C0339573\n",
      "UMLS:C0376358\n",
      "UMLS:C0393541\n",
      "UMLS:C0522224\n",
      "UMLS:C0525045\n",
      "UMLS:C0878544\n",
      "UMLS:C1260409\n",
      "UMLS:C1269683\n",
      "UMLS:C1449563\n",
      "UMLS:C1510586\n",
      "UMLS:C1535926\n",
      "UMLS:C1862939\n",
      "UMLS:C3554373\n",
      "UMLS:C5681306\n"
     ]
    }
   ],
   "source": [
    "for node, ndata in pygraph.nodes(data=True):\n",
    "    if not ndata:\n",
    "        print(node)\n",
    "\n",
    "    # try:\n",
    "    #     if \"UMLS\" in node:\n",
    "    #         print(node, ndata)\n",
    "    # except:\n",
    "    #     print(node, ndata)\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubchem.compound:55245 UMLS:C0000786 {'label': 'treats', 'datasource': 'OpenTargets'}\n"
     ]
    }
   ],
   "source": [
    "for source, target, data in pygraph.edges(data=True):\n",
    "    if source == \"UMLS:C0000786\" or target == \"UMLS:C0000786\":\n",
    "        print(source, target, data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.3. Cytoscape\n",
    "Make sure that the Cytoscape is open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyBiodatafuse.graph import cytoscape\n",
    "\n",
    "# cytoscape.load_graph(pygraph, network_name=\"Test network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.4. Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyBiodatafuse.graph import neo4j\n",
    "\n",
    "# neo4j.save_graph_to_graphml(pygraph, \"networkx_graph_test.graphml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Steps to load the graph in Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add `.graphml` file in **import** subfolder of the DBMS folder\n",
    "- Install apoc plugin\n",
    "- Create `apoc.conf` file:\n",
    "    ```\n",
    "    apoc.trigger.enabled=true\n",
    "    apoc.import.file.enabled=true\n",
    "    apoc.export.file.enabled=true\n",
    "    apoc.import.file.use_neo4j_config=true\n",
    "    ```\n",
    "- Add `apoc.conf` file to **conf** subfolder of the DBMS folder\n",
    "- Open Neo4j Browser\n",
    "- (Optionl, only run if you have imported a graph  before) Remove all the nodes before importing `.graphml` file\n",
    "\n",
    "    ```MATCH (n) DETACH DELETE n```\n",
    "\n",
    "- Import `.graphml` file\n",
    "\n",
    "    ```call apoc.import.graphml('file:///networkx_graph_test.graphml',{readLabels:TRUE})```\n",
    "\n",
    "- Add indexes after importing the graph for improving the performance of queries\n",
    "\n",
    "    ```\n",
    "    create index Gene for (n:Gene) on (n.node_type)\n",
    "    create index Pathway for (n:Pathway) on (n.node_type)\n",
    "    create index `Biological Process` for (n:`Biological Process`) on (n.node_type)\n",
    "    create index `Molecular Function` for (n:`Molecular Function`) on (n.node_type)\n",
    "    create index `Cellular Component` for (n:`Cellular Component`) on (n.node_type)\n",
    "    create index Disease for (n:Disease) on (n.node_type)\n",
    "    create index Compound for (n:Compound) on (n.node_type)\n",
    "    create index `Side Effect` for (n:`Side Effect`) on (n.node_type)\n",
    "    ```\n",
    "    \n",
    "\n",
    "- Count the number of each node type\n",
    "    - total (```MATCH (n) RETURN count(n)```) \n",
    "        - Gene (```MATCH (n:Gene) RETURN count(n)```)\n",
    "        - Pathway (```MATCH (n:Pathway) RETURN count(n)```)\n",
    "            - WikiPathways (```MATCH (n:Pathway {source: \"WikiPathways\"}) RETURN count(n)```) \n",
    "            - OpenTargets, Reactome (```MATCH (n:Pathway {source: \"OpenTargets\"}) RETURN count(n)```) \n",
    "            - MINERVA (```MATCH (n:Pathway {source: \"MINERVA\"}) RETURN count(n)```) \n",
    "        - Biological Process (```MATCH (n:`Biological Process`) RETURN count(n)```) \n",
    "        - Molecular Function (```MATCH (n:`Molecular Function`) RETURN count(n)```) \n",
    "        - Cellular Component (```MATCH (n:`Cellular Component`) RETURN count(n)```) \n",
    "        - Disease (```MATCH (n:Disease) RETURN count(n)```) \n",
    "        - Compound (```MATCH (n:Compound) RETURN count(n)```)\n",
    "        - Side Effect (```MATCH (n:`Side Effect`) RETURN count(n)```) \n",
    "- Count the number of each edge type\n",
    "    - total (```MATCH ()-[r]->() RETURN count(r)```) \n",
    "        - interacts_with (```MATCH ()-[r:interacts_with]->() RETURN count(r)```) \n",
    "        - part_of (```MATCH ()-[r:part_of]->() RETURN count(r)```) \n",
    "            - WikiPathways (```MATCH ()-[r:part_of {source: \"WikiPathways\"}]->() RETURN count(r)```) \n",
    "            - OpenTargets, Reactome (```MATCH ()-[r:part_of {source: \"OpenTargets\"}]->() RETURN count(r)```) \n",
    "            - MINERVA (```MATCH ()-[r:part_of {source: \"MINERVA\"}]->() RETURN count(r)```) \n",
    "        - activates (```MATCH ()-[r:activates]->() RETURN count(r)```) \n",
    "        - treats (```MATCH ()-[r:treats]->() RETURN count(r)```) \n",
    "        - has_side_effect (```MATCH ()-[r:has_side_effect]->() RETURN count(r)```) \n",
    "        - inhibits (```MATCH ()-[r:inhibits]->() RETURN count(r)```) = 71\n",
    "        - associated_with (```MATCH ()-[r:associated_with]->() RETURN count(r)```) \n",
    "\n",
    "- Export the graph as a `.csv` file\n",
    "\n",
    "    ```call apoc.export.csv.all(\"networkx_graph_test.csv\",{})```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.5. GraphDB (RDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a BDFGraph\n",
    "# bdf = BDFGraph(\n",
    "#     base_uri=\"https://biodatafuse.org/example/\",\n",
    "#     version_iri=\"https://biodatafuse.org/example/test.owl\",\n",
    "#     orcid=\"https://orcid.org/0000-0002-4166-7093\",\n",
    "#     author=\"Javier Millan Acosta\",\n",
    "# )\n",
    "\n",
    "# bdf.generate_rdf(combined_df, combined_metadata)  # Generate the RDF from the (meta)data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bdf.serialize(\n",
    "#     os.path.join(base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_graph.ttl\"),\n",
    "#     format=\"ttl\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.5.1. Generate prefixes SHACL\n",
    "\n",
    "SHACL graphs defining namespaces and prefixes can be loaded into SPARQL endpoints to avoid having to declare prefixes in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use without parameters (defaults, does not save file)\n",
    "# bdf.shacl_prefixes()\n",
    "# # or Use with parameters\n",
    "# bdf.shacl_prefixes(\n",
    "#     path=os.path.join(base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_prefixes.ttl\"),\n",
    "#     namespaces=None,  # Optional, add more namespaces with a dictionary of {prefix:namespace,}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.5.2. Use [`shexer`](https://github.com/DaniFdezAlvarez/shexer/) to retrieve the RDF shapes\n",
    "\n",
    "The `shexer` library is used to retrieve the shapes of the graph in SHACL (https://www.w3.org/TR/shacl/) and ShEx (https://shex.io/shex-semantics/).\n",
    "\n",
    "- **SHACL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use without parameters (defaults)\n",
    "# # bdf.shacl()\n",
    "\n",
    "# # Or use with parameters\n",
    "# bdf.shacl(\n",
    "#     path=os.path.join(\n",
    "#         base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shacl.ttl\"\n",
    "#     ),  # Set a path for TTL serialization\n",
    "#     threshold=0.001,\n",
    "#     uml_figure_path=os.path.join(\n",
    "#         base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shacl.png\"\n",
    "#     ),  # Set a path for diagram\n",
    "# )\n",
    "\n",
    "# # Display the UML figure\n",
    "# display(\n",
    "#     Image(\n",
    "#         os.path.join(\n",
    "#             base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shacl.png\"\n",
    "#         )\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ShEx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use without parameters (defaults)\n",
    "# bdf.shex()\n",
    "\n",
    "# Or use with parameters\n",
    "# bdf.shex(\n",
    "#     path=os.path.join(\n",
    "#         base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shex.ttl\"\n",
    "#     ),  # Set a path for TTL serialization\n",
    "#     threshold=0.001,\n",
    "#     uml_figure_path=os.path.join(\n",
    "#         base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shex.png\"\n",
    "#     ),  # Set a path for diagram\n",
    "# )\n",
    "\n",
    "# # Display the UML figure\n",
    "# display(\n",
    "#     Image(\n",
    "#         os.path.join(base_dir, \"examples\", \"data\", \"gene_to_graph_workflow\", \"BDF_example_shex.png\")\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elapsed time for the workflow, if ran in block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "# hours = elapsed_time // 3600\n",
    "# minutes = (elapsed_time % 3600) // 60\n",
    "# seconds = elapsed_time % 60\n",
    "# milliseconds = (elapsed_time % 1) * 1000\n",
    "\n",
    "# # Display elapsed time in h:m:s:ms\n",
    "# print(f\"Elapsed Time: {int(hours)}h {int(minutes)}m {int(seconds)}s {int(milliseconds)}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8.5.3 Set up a virtuoso endpoint to query the RDF graph\n",
    "\n",
    "[This repository](https://github.com/jmillanacosta/fast-virtuoso) provides a quick way to set up a local Virtuoso endpoint using its docker image.\n",
    "\n",
    "Upload the prefixes (`bdf.shacl_prefixes(path=\"your/path\")`) and the BDF graph generated above (`bdf.serialize(\"your/path\", format=\"ttl\")`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to send some sample SELECT queries and return the response in a pandas DataFrame\n",
    "# import requests\n",
    "\n",
    "\n",
    "# def send_sparql_query(query, endpoint=\"http://localhost:8899/sparql\", format=\"text/csv\"):\n",
    "#     headers = {\"Accept\": format}\n",
    "#     params = {\"query\": query}\n",
    "#     response = requests.get(endpoint, headers=headers, params=params)\n",
    "\n",
    "#     # Check if request was successful\n",
    "#     if response.status_code == 200:\n",
    "#         if format == \"text/csv\":\n",
    "#             # Convert CSV response to pandas DataFrame\n",
    "#             from io import StringIO\n",
    "\n",
    "#             csv_data = StringIO(response.text)\n",
    "#             return pd.read_csv(csv_data)\n",
    "#         else:\n",
    "#             return response.text  # For other formats if needed\n",
    "#     else:\n",
    "#         raise Exception(f\"Query failed with status code {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdflib import RDF, RDFS, SH, Graph\n",
    "\n",
    "# # Parse the query graph\n",
    "# # Load the graph\n",
    "# query_g = Graph()\n",
    "# with open(\"examples/SPARQL/queries.ttl\", \"r\") as f:\n",
    "#     query_g.parse(f, format=\"turtle\")\n",
    "\n",
    "# # Extract queries and comments into a list of dictionaries\n",
    "# queries_list = []\n",
    "# for s in query_g.subjects(RDF.type, SH.SPARQLSelectExecutable):\n",
    "#     query_text = query_g.value(s, SH.select)\n",
    "#     comment = query_g.value(s, RDFS.comment)\n",
    "\n",
    "#     if query_text and comment:\n",
    "#         # Append a dictionary for each query and its comment\n",
    "#         queries_list.append({\"comment\": comment.value, \"query\": query_text.value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_0 = send_sparql_query(queries_list[0][\"query\"])\n",
    "# print(queries_list[0][\"comment\"])\n",
    "# print(queries_list[0][\"query\"])\n",
    "# query_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_3 = send_sparql_query(queries_list[3][\"query\"])\n",
    "# print(queries_list[3][\"query\"])\n",
    "# print(queries_list[3][\"comment\"])\n",
    "# query_3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pybiodatafuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
